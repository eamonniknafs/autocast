{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = <YOUR API KEY>\n",
    "openai.api_key = api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "autocast_questions = json.load(open('autocast_questions.json')) # from the Autocast dataset\n",
    "test_questions = json.load(open('autocast_competition_test_set.json'))\n",
    "test_ids = [q['id'] for q in test_questions]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = []\n",
    "for item in autocast_questions:\n",
    "    if item[\"answer\"] != None and item[\"id\"] not in test_ids: # take care of duplicate in training and test set \n",
    "        new_item = {\"prompt\": item[\"question\"] + \" choices: \" + str(item[\"choices\"]) + \" ->\", \"completion\": \" \" + str(item[\"answer\"]) + \".\\n\"}\n",
    "        new_data.append(new_item)\n",
    "with open(\"autocast_questions_gpt3.json\", \"w\") as f:\n",
    "    json.dump(new_data, f)\n",
    "    \n",
    "file_name = \"autocast_questions_gpt3.jsonl\"\n",
    "with open(file_name, \"w\") as output_file:\n",
    "    for entry in new_data:\n",
    "        json.dump(entry, output_file)\n",
    "        output_file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing...\n",
      "\n",
      "- Your file contains 2797 prompt-completion pairs\n",
      "- Based on your data it seems like you're trying to fine-tune a model for classification\n",
      "- For classification, we recommend you try one of the faster and cheaper models, such as `ada`\n",
      "- For classification, you can estimate the expected model performance by keeping a held out dataset, which is not used for training\n",
      "- There are 19 duplicated prompt-completion sets. These are rows: [1393, 1394, 1395, 1396, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1408, 1409, 1748, 1946]\n",
      "- All prompts end with suffix ` ->`\n",
      "\n",
      "Based on the analysis we will perform the following actions:\n",
      "- [Recommended] Remove 19 duplicate rows [Y/n]: ^C\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!openai tools fine_tunes.prepare_data -f autocast_questions_gpt3.jsonl"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning GPT3 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<File file id=file-j290Y5UZP7iccNMInZyzQbbX at 0x7fef2000f9a0> JSON: {\n",
       "  \"bytes\": 586222,\n",
       "  \"created_at\": 1678246186,\n",
       "  \"filename\": \"file\",\n",
       "  \"id\": \"file-j290Y5UZP7iccNMInZyzQbbX\",\n",
       "  \"object\": \"file\",\n",
       "  \"purpose\": \"fine-tune\",\n",
       "  \"status\": \"uploaded\",\n",
       "  \"status_details\": null\n",
       "}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upload_response = openai.File.create(file=open(\"autocast_questions_gpt3.jsonl\", \"rb\"), purpose=\"fine-tune\")\n",
    "file_id = upload_response.id\n",
    "upload_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<FineTune fine-tune id=ft-Mu85TtcUiHmndBacW6XqfK4I at 0x7fef9415f1d0> JSON: {\n",
       "  \"created_at\": 1678246189,\n",
       "  \"events\": [\n",
       "    {\n",
       "      \"created_at\": 1678246189,\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Created fine-tune: ft-Mu85TtcUiHmndBacW6XqfK4I\",\n",
       "      \"object\": \"fine-tune-event\"\n",
       "    }\n",
       "  ],\n",
       "  \"fine_tuned_model\": null,\n",
       "  \"hyperparams\": {\n",
       "    \"batch_size\": null,\n",
       "    \"learning_rate_multiplier\": null,\n",
       "    \"n_epochs\": 4,\n",
       "    \"prompt_loss_weight\": 0.01\n",
       "  },\n",
       "  \"id\": \"ft-Mu85TtcUiHmndBacW6XqfK4I\",\n",
       "  \"model\": \"ada\",\n",
       "  \"object\": \"fine-tune\",\n",
       "  \"organization_id\": \"org-0Vb7q2Rndj3zUuGWDYjsJAMr\",\n",
       "  \"result_files\": [],\n",
       "  \"status\": \"pending\",\n",
       "  \"training_files\": [\n",
       "    {\n",
       "      \"bytes\": 586222,\n",
       "      \"created_at\": 1678246186,\n",
       "      \"filename\": \"file\",\n",
       "      \"id\": \"file-j290Y5UZP7iccNMInZyzQbbX\",\n",
       "      \"object\": \"file\",\n",
       "      \"purpose\": \"fine-tune\",\n",
       "      \"status\": \"uploaded\",\n",
       "      \"status_details\": null\n",
       "    }\n",
       "  ],\n",
       "  \"updated_at\": 1678246189,\n",
       "  \"validation_files\": []\n",
       "}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fine_tune_response = openai.FineTune.create(training_file=file_id, model=\"ada\")\n",
    "fine_tune_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'object': 'fine-tune', 'id': 'ft-Mu85TtcUiHmndBacW6XqfK4I', 'hyperparams': {'n_epochs': 4, 'batch_size': None, 'prompt_loss_weight': 0.01, 'learning_rate_multiplier': None}, 'organization_id': 'org-0Vb7q2Rndj3zUuGWDYjsJAMr', 'model': 'ada', 'training_files': [{'object': 'file', 'id': 'file-j290Y5UZP7iccNMInZyzQbbX', 'purpose': 'fine-tune', 'filename': 'file', 'bytes': 586222, 'created_at': 1678246186, 'status': 'processed', 'status_details': None}], 'validation_files': [], 'result_files': [], 'created_at': 1678246189, 'updated_at': 1678246189, 'status': 'pending', 'fine_tuned_model': None, 'events': [{'object': 'fine-tune-event', 'level': 'info', 'message': 'Created fine-tune: ft-Mu85TtcUiHmndBacW6XqfK4I', 'created_at': 1678246189}]}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Replace YOUR_API_KEY with your OpenAI API key\n",
    "headers = {\n",
    "    'Content-Type': 'application/json',\n",
    "    'Authorization': f'Bearer <YOUR API KEY>'\n",
    "}\n",
    "\n",
    "# Replace FINE_TUNE_ID with the ID of your fine-tuning job\n",
    "# previous \n",
    "response = requests.get('https://api.openai.com/v1/fine-tunes/<YOUR JOB ID', headers=headers)\n",
    "\n",
    "# Print the response\n",
    "print(response.json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject list at 0x7fef94616b80> JSON: {\n",
       "  \"data\": [\n",
       "    {\n",
       "      \"created_at\": 1678246189,\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Created fine-tune: ft-Mu85TtcUiHmndBacW6XqfK4I\",\n",
       "      \"object\": \"fine-tune-event\"\n",
       "    },\n",
       "    {\n",
       "      \"created_at\": 1678246614,\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Fine-tune costs $0.21\",\n",
       "      \"object\": \"fine-tune-event\"\n",
       "    },\n",
       "    {\n",
       "      \"created_at\": 1678246614,\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Fine-tune enqueued. Queue number: 3\",\n",
       "      \"object\": \"fine-tune-event\"\n",
       "    },\n",
       "    {\n",
       "      \"created_at\": 1678246661,\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Fine-tune is in the queue. Queue number: 2\",\n",
       "      \"object\": \"fine-tune-event\"\n",
       "    },\n",
       "    {\n",
       "      \"created_at\": 1678246704,\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Fine-tune is in the queue. Queue number: 1\",\n",
       "      \"object\": \"fine-tune-event\"\n",
       "    },\n",
       "    {\n",
       "      \"created_at\": 1678247029,\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Fine-tune is in the queue. Queue number: 0\",\n",
       "      \"object\": \"fine-tune-event\"\n",
       "    },\n",
       "    {\n",
       "      \"created_at\": 1678247072,\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Fine-tune started\",\n",
       "      \"object\": \"fine-tune-event\"\n",
       "    },\n",
       "    {\n",
       "      \"created_at\": 1678247361,\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Completed epoch 1/4\",\n",
       "      \"object\": \"fine-tune-event\"\n",
       "    },\n",
       "    {\n",
       "      \"created_at\": 1678247632,\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Completed epoch 2/4\",\n",
       "      \"object\": \"fine-tune-event\"\n",
       "    },\n",
       "    {\n",
       "      \"created_at\": 1678247905,\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Completed epoch 3/4\",\n",
       "      \"object\": \"fine-tune-event\"\n",
       "    },\n",
       "    {\n",
       "      \"created_at\": 1678248177,\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Completed epoch 4/4\",\n",
       "      \"object\": \"fine-tune-event\"\n",
       "    },\n",
       "    {\n",
       "      \"created_at\": 1678248192,\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Uploaded model: ada:ft-personal-2023-03-08-04-03-12\",\n",
       "      \"object\": \"fine-tune-event\"\n",
       "    },\n",
       "    {\n",
       "      \"created_at\": 1678248193,\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Uploaded result file: file-sRJ0pm3ndtL1S86FkwM0YNDs\",\n",
       "      \"object\": \"fine-tune-event\"\n",
       "    },\n",
       "    {\n",
       "      \"created_at\": 1678248193,\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Fine-tune succeeded\",\n",
       "      \"object\": \"fine-tune-event\"\n",
       "    }\n",
       "  ],\n",
       "  \"object\": \"list\"\n",
       "}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fine_tune_events = openai.FineTune.list_events(id=<YOUR JOB ID>)\n",
    "fine_tune_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ada:ft-personal-2023-03-08-04-03-12'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieve_response = openai.FineTune.retrieve(<YOUR JOB ID>)\n",
    "fine_tuned_model = retrieve_response.fine_tuned_model\n",
    "fine_tuned_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer = openai.Completion.create(model=\"<YOUR MODEL ID>\", prompt=\"Before 1 July 2021, will the Chilean government pass legislation that caps administrative fees and/or operating profits of the country's pension fund managers? choices: ['yes', 'no] ->\", \n",
    "max_tokens=10, temperature=0) \n",
    "answer[\"choices\"][0][\"text\"].strip().split(\".\\n\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt3(question):\n",
    "    answer = openai.Completion.create(model= <YOUR MODEL ID>, prompt=question[\"question\"] + \" choices: \" + str(question[\"choices\"]) + \" ->\", max_tokens=10, temperature=0) \n",
    "    return answer[\"choices\"][0][\"text\"].strip().split(\".\\n\")[0]\n",
    "\n",
    "def calibrated_random_baseline_model(question):\n",
    "    ans = gpt3(question)\n",
    "    if question['qtype'] == 't/f':\n",
    "        if ans == \"None\" or (ans != \"yes\" and ans != \"no\"):\n",
    "            return np.zeros(2)\n",
    "        pred_idx = 0 if ans == 'no' else 1        \n",
    "        pred = np.zeros(2)\n",
    "        pred[pred_idx] = 1\n",
    "        return pred \n",
    "    elif question['qtype'] == 'mc':\n",
    "        if ans == \"None\" or not (\"Z\" <= ans <= \"A\"):\n",
    "            return np.zeros(len(question['choices']))\n",
    "        pred_idx = ord(ans) - ord('A')\n",
    "        pred = np.zeros(len(question['choices']))\n",
    "        if pred_idx < len(pred):\n",
    "            pred[pred_idx] = 1\n",
    "        return pred \n",
    "    elif question['qtype'] == 'num':\n",
    "        return float(ans.strip(\".\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get performance on the Autocast train set\n",
    "\n",
    "Note that the Autocast dataset contains questions in the competition test set. Those should not be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "answers = []\n",
    "qtypes = []\n",
    "for question in autocast_questions:\n",
    "    if question['id'] in test_ids: # skipping questions in the competition test set\n",
    "        continue\n",
    "    if question['answer'] is None: # skipping questions without answer\n",
    "        continue\n",
    "    preds.append(calibrated_random_baseline_model(question))\n",
    "    if question['qtype'] == 't/f':\n",
    "        ans_idx = 0 if question['answer'] == 'no' else 1\n",
    "        ans = np.zeros(len(question['choices']))\n",
    "        ans[ans_idx] = 1\n",
    "        qtypes.append('t/f')\n",
    "    elif question['qtype'] == 'mc':\n",
    "        ans_idx = ord(question['answer']) - ord('A')\n",
    "        ans = np.zeros(len(question['choices']))\n",
    "        ans[ans_idx] = 1\n",
    "        qtypes.append('mc')\n",
    "    elif question['qtype'] == 'num':\n",
    "        ans = float(question['answer'])\n",
    "        qtypes.append('num')\n",
    "    answers.append(ans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def brier_score(probabilities, answer_probabilities):\n",
    "    return ((probabilities - answer_probabilities) ** 2).sum() / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T/F: 11.07, MCQ: 50.00, NUM: 15.33\n",
      "Combined Metric: 76.40\n"
     ]
    }
   ],
   "source": [
    "tf_results, mc_results, num_results = [],[],[]\n",
    "for p, a, qtype in zip(preds, answers, qtypes):\n",
    "    \n",
    "    if qtype == 't/f':      \n",
    "        tf_results.append(brier_score(p, a))\n",
    "    elif qtype == 'mc':\n",
    "        if len(p) == len(a):\n",
    "            mc_results.append(brier_score(p, a))\n",
    "    else:\n",
    "        num_results.append(np.abs(float(p) - a))\n",
    "print(f\"T/F: {np.mean(tf_results)*100:.2f}, MCQ: {np.mean(mc_results)*100:.2f}, NUM: {np.mean(num_results)*100:.2f}\")\n",
    "print(f\"Combined Metric: {(np.mean(tf_results) + np.mean(mc_results) + np.mean(num_results))*100:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "for question in test_questions:\n",
    "    preds.append(calibrated_random_baseline_model(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updating: predictions.pkl (deflated 76%)\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('submission'):\n",
    "    os.makedirs('submission')\n",
    "\n",
    "with open(os.path.join('submission', 'predictions.pkl'), 'wb') as f:\n",
    "    pickle.dump(preds, f, protocol=2)\n",
    "\n",
    "!cd submission && zip ../submission.zip ./* && cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md                          example_submission_gpt3.ipynb\n",
      "autocast_competition_test_set.json predictions_correct.pkl\n",
      "autocast_questions.json            \u001b[34msubmission\u001b[m\u001b[m\n",
      "autocast_questions_gpt3.json       submission.zip\n",
      "autocast_questions_gpt3.jsonl      test.ipynb\n",
      "example_submission.ipynb\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "61b4062b24dfb1010f420dad5aa3bd73a4d2af47d0ec44eafec465a35a9d7239"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
